# üöÄ LOCAL AI ARCHITECTURE: MCP vs. RAG
### Architecting Intelligence from Raw Data Units

> **Project Status:** Production-Ready | **Data Integrity:** 99.90% | **Architecture:** RAG-Enabled

---

### üìñ The Engineering Mission
This repository documents the end-to-end transformation of high-volume, unstructured industry data into a semantically-aware AI knowledge system. Processing a total of **13,952 data units** extracted from UK industry reports, this project bridges the gap between raw information and actionable intelligence.

### üèóÔ∏è Pipeline Architecture at a Glance
The system is built on a four-stage industrial pipeline:

1.  **Validation:** A rigorous "Gatekeeper" phase ensuring a **99.90% integrity rate** across 139 JSON data chunks.
2.  **Enrichment:** A semantic taxonomy layer that categorizes data into **Public Policy**, **Business Impact**, and **Future of Work** sectors.
3.  **Vectorization:** Deployment of a local **Sentence-Transformer** model to map 13,938 validated units into a 384-dimensional neural space.
4.  **Retrieval (RAG):** A custom-built query engine that provides context-filtered, high-precision search results using Cosine Similarity.

*This project serves as a blueprint for local-first AI architectures, prioritizing data privacy, technical rigor, and semantic accuracy.*

---

## üìå Project Overview
This project demonstrates the end-to-end engineering required to transform raw data into a professional AI knowledge system. Whether working with a custom dataset or your own proprietary data, this repository provides the blueprint for two distinct integration paths:

* **MCP (Model Context Protocol):** Direct tool-based connection.
* **RAG (Retrieval-Augmented Generation):** Semantic vector-based memory.

The objective is to guide the transition from raw, fragmented files to a production-ready AI context.

---

## üõ†Ô∏è THE 5-STAGE ENGINEERING PIPELINE

<details>
<summary><b>Click to expand the 5-Stage Curriculum details</b></summary>

* **Stage 1: Data Validation & Schema Enforcement:** We implement scripts to ensure every data unit adheres to a strict schema, removing duplicates and correcting encoding errors.
* **Stage 2: Semantic Metadata Enrichment:** To improve retrieval accuracy, we programmatically tag chunks with relevant metadata (Zone A, B, or C).
* **Stage 3: Vectorization & Neural Embeddings:** Text is converted into high-dimensional vectors to enable Semantic Search based on meaning.
* **Stage 4: Vector Database Implementation:** Utilizing specialized local storage for sub-second retrieval speeds.
* **Stage 5: Inference & Pipeline Integration:** Connecting local engines (like Ollama) to generate grounded answers.

</details>

---

## üè∑Ô∏è STAGE 2: SEMANTIC TAXONOMY

To transform raw data into a structured knowledge base, we categorize each unit into one of three thematic "Zones":

| Zone | Category | Logic / Keywords | Goal |
| :--- | :--- | :--- | :--- |
| **Zone A** | **Public & Policy** | Government, NHS, Ethics, Safety | Regulatory guardrails. |
| **Zone B** | **Business Impact** | Investment, Market, Revenue, Startups | Economic growth. |
| **Zone C** | **Future of Work** | Skills, Automation, Jobs, Training | Labor evolution. |

### üìä Latest Audit Statistics
* **Total Individual Data Units:** 13,952
* **Successfully Validated:** 13,938
* **Integrity Rate:** 99.90%

---

## üß† STAGE 3: NEURAL VECTORIZATION

To enable semantic search, the enriched dataset was transformed into dense vector embeddings. This allows the system to retrieve information based on **meaning** rather than just keyword matching.

### üî¨ Technical Specifications
| Attribute | Specification |
| :--- | :--- |
| **Model** | `all-MiniLM-L6-v2` (Sentence-Transformers) |
| **Dimensionality** | 384-dimensional dense vectors |
| **Total Vectors** | 13,938 |
| **Format** | Compressed NumPy Archive (.npz) |

---

## üöÄ STAGE 4: FINAL VALIDATION & RESULTS

The pipeline successfully processed **13,952 total units** with a **99.90% integrity rate**.

**Example Query Success:**
When asked about *'Government safety standards for AI'*, the RAG engine successfully bypassed technical code noise to retrieve high-relevance policymaking evidence from **Zone A**, citing responsibilities from international bodies like the **OECD**.


---

## üõ†Ô∏è Execution Roadmap

To reproduce the results of this project, execute the scripts in the following sequence:

### 1Ô∏è‚É£ Data Validation
```bash
python validate_chunks.py

Ensures the 13,952 units meet the 99.90% integrity threshold.

2Ô∏è‚É£ Semantic Enrichment
Bash

python enrich_metadata.py
Applies the Zone A/B/C taxonomy to the validated JSON units.

3Ô∏è‚É£ Neural Vectorization
Bash

python create_embeddings.py
Generates the 384-dimensional mathematical coordinates for semantic search.

4Ô∏è‚É£ RAG Querying
Bash

python query_engine.py
Launches the interactive terminal to ask questions and retrieve context-aware answers.

üìÇ Repository Assets
Core Scripts: validate_chunks.py, enrich_metadata.py, create_embeddings.py, query_engine.py

Data Store: semantic_vectors.npz (Neural memory archive)

Reports: stage_1_validation_report.md


---

### üëÅÔ∏è ONLY FOR YOUR EYES: Final Polish
If you paste the block above exactly as written, the spacing will force GitHub to render the tables and the code blocks properly. 

**Does the "Preview" tab on GitHub look clean now with the tables and icons separated?** Once you confirm, we can finish by writing a professional LinkedIn post to celebrate your 99.90% validation achievement!
